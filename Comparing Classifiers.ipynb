{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Classifiers\n",
    "## Firstly\n",
    "This part I'm just defining classes described and defined [here](https://github.com/jonchar/ml-python/blob/master/SVM.ipynb)\n",
    "\n",
    "So probably just scroll down a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array,zeros,vstack,repeat,ones,eye,ndarray\n",
    "from cvxopt import *\n",
    "import pylab as pl\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __call__(self, a, b):\n",
    "        x = np.array(a)\n",
    "        y = np.array(b)\n",
    "        y = np.transpose(y)\n",
    "        return np.dot(x, y)\n",
    "\n",
    "class Polynomial():\n",
    "    def __call__(self, a, b, p=2):\n",
    "        x = np.array(a)\n",
    "        y = np.array(b)\n",
    "        y = np.transpose(y)\n",
    "        return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "class Gaussian():\n",
    "    def __call__(self, a, b, sigma=5.0):\n",
    "        x = np.array(a)\n",
    "        y = np.array(b)\n",
    "        y = np.transpose(y)\n",
    "        return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class svm_problem():\n",
    "    def __init__(self, C=0.1, gamma=0.001, delta=100.0, kernel=Gaussian()):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.delta = delta\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def set_variables(self, X, Xstar, Y):\n",
    "        if(isinstance(X, ndarray)):\n",
    "            self.X = X\n",
    "        else:\n",
    "            self.X = array(X)\n",
    "        if(isinstance(Xstar, ndarray)):\n",
    "            self.Xstar = Xstar\n",
    "        else:\n",
    "            self.Xstar = array(Xstar)\n",
    "        if(isinstance(Y, ndarray)):\n",
    "            self.Y = Y\n",
    "        else:\n",
    "            self.Y = array(Y)\n",
    "        self.num = len(self.X)\n",
    "        self.dimensions = len(self.X[0])\n",
    "        self.xi_xj = self.gram_matrix(self.X, self.X)\n",
    "        self.xstari_xstarj = self.gram_matrix(self.Xstar, self.Xstar)\n",
    "        self.yi_yj = self.gram_matrix(self.Y, self.Y)\n",
    "\n",
    "    def gram_matrix(self, X1, X2):\n",
    "        K = zeros((len(X1), len(X1)))\n",
    "        for i in range(len(X1)):\n",
    "            for j in range(len(X1)):\n",
    "                K[i,j] = self.kernel(X1[i], X2[j])\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class classifier():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        self.alphas = []\n",
    "        self.support_vectors = []\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.sign(np.dot(self.w,x)+self.b)\n",
    "    \n",
    "    def f_star(self, x, y): # This won't make sense now, but we come back to it later\n",
    "        return y*(np.dot(self.w,x)+self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def get_name(self):\n",
    "        return \"SVM\"\n",
    "    def train(self, x, prob : svm_problem):\n",
    "        x = x\n",
    "        y = prob.Y\n",
    "        C = prob.C\n",
    "\n",
    "        NUM = x.shape[0]\n",
    "        DIM = x.shape[1]\n",
    "\n",
    "        K = y[:, None] * x # Yeah, this is a bit different so that it can work on x and x*\n",
    "        K = np.dot(K, K.T)\n",
    "        P = matrix(K, tc='d')\n",
    "        q = matrix(-np.ones((NUM, 1)), tc='d')\n",
    "        G1 = -np.eye(NUM)\n",
    "        G2 = np.eye(NUM)\n",
    "        G = np.vstack((G1, G2))\n",
    "        G = matrix(G, tc='d')\n",
    "        h1 = np.zeros(NUM).reshape(-1,1)\n",
    "        h2 = np.repeat(C, NUM).reshape(-1,1)\n",
    "        h = np.vstack((h1, h2))\n",
    "        h = matrix(h, tc='d')\n",
    "        A = matrix(y.reshape(1, -1), tc='d')\n",
    "        b = matrix(np.zeros(1), tc='d')\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alphas = np.array(sol['x'])\n",
    "        w = np.sum(alphas * y[:, None] * x, axis = 0)\n",
    "        bacond1 = (alphas > 1e-8)\n",
    "        bacond2 = (alphas < (C))\n",
    "        bcond = np.array([a and b for a, b in zip(bacond1, bacond2)]).flatten()\n",
    "        yS = y[bcond]\n",
    "        xS = x[bcond]\n",
    "        aS = alphas[bcond]\n",
    "        sumTotal = 0\n",
    "        for s in range(len(yS)):\n",
    "            innerTotal = 0\n",
    "            for m in range(len(yS)):\n",
    "                am = aS[m]\n",
    "                ym = yS[m]\n",
    "                xm_xs = prob.kernel(xS[m], xS[s])\n",
    "                innerTotal += am*ym*xm_xs\n",
    "            sumTotal += yS[s] - innerTotal\n",
    "        bias = sumTotal/len(yS)\n",
    "        clf = classifier()\n",
    "        clf.w = w\n",
    "        clf.b = bias[0]\n",
    "        clf.alphas = alphas\n",
    "        clf.support_vectors = x[bacond1.flatten()]\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMdp_simp():\n",
    "    def get_name(self):\n",
    "        return \"SVM+ - simplified approach\"\n",
    "    def train(self, prob : svm_problem):\n",
    "        x = prob.X\n",
    "        xStar = prob.Xstar\n",
    "        y = prob.Y\n",
    "        C = prob.C\n",
    "\n",
    "        NUM = x.shape[0]\n",
    "        DIM = x.shape[1]\n",
    "        \n",
    "        svm = SVM()\n",
    "        xStar_clf = svm.train(xStar, prob)\n",
    "        \n",
    "        xi_star_amended = np.zeros(prob.num)\n",
    "        for i in range(prob.num):\n",
    "            output = (1- prob.Y[i]*(np.dot(xStar_clf.w,prob.Xstar[i])+xStar_clf.b))\n",
    "            xi_star_amended[i] = max(0, output)\n",
    "\n",
    "        Ky = prob.yi_yj\n",
    "        Kx = prob.xi_xj\n",
    "        K = Ky*Kx\n",
    "        P = matrix(K, tc='d')\n",
    "        q = matrix(-np.ones((NUM, 1)), tc='d')\n",
    "        G1 = -np.eye(NUM)\n",
    "        G2 = np.eye(NUM)\n",
    "        G3 = xi_star_amended.reshape(1,-1)\n",
    "        G = np.vstack((G1, G2))\n",
    "        G = np.vstack((G, G3))\n",
    "        G = matrix(G, tc='d')\n",
    "        h1 = np.zeros(NUM).reshape(-1,1)\n",
    "        h2 = np.repeat(C, NUM).reshape(-1,1)\n",
    "        h3 = sum(xi_star_amended)*C\n",
    "        h = np.vstack((h1, h2))\n",
    "        h = np.vstack((h, h3))\n",
    "        h = matrix(h, tc='d')\n",
    "        A = matrix(y.reshape(1, -1), tc='d')\n",
    "        b = matrix(np.zeros(1), tc='d')\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alphas = np.array(sol['x'])\n",
    "        w = np.sum(alphas * y[:, None] * x, axis = 0)\n",
    "\n",
    "        bacond1 = (alphas > 1e-8)\n",
    "        bacond2 = (alphas < C)\n",
    "        bcond = np.array([a and b for a, b in zip(bacond1, bacond2)]).flatten()\n",
    "\n",
    "        yS = y[bcond]\n",
    "        xS = x[bcond]\n",
    "        aS = alphas[bcond]\n",
    "\n",
    "        sumTotal = 0\n",
    "        for s in range(len(yS)):\n",
    "            innerTotal = 0\n",
    "            for m in range(len(yS)):\n",
    "                am = aS[m]\n",
    "                ym = yS[m]\n",
    "                xm_xs = prob.kernel(xS[m], xS[s])\n",
    "                innerTotal += am*ym*xm_xs\n",
    "            sumTotal += yS[s] - innerTotal\n",
    "\n",
    "        bias = sumTotal/len(yS)\n",
    "\n",
    "        clf = classifier()\n",
    "        clf.w = w\n",
    "        clf.b = bias\n",
    "        clf.alphas = alphas\n",
    "        clf.support_vectors = prob.X[bacond1.flatten()]\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMdp():\n",
    "    def get_name(self):\n",
    "        return \"SVM+\"\n",
    "    def train(self, prob : svm_problem):\n",
    "        kernel = prob.kernel\n",
    "        C = prob.C\n",
    "\n",
    "        L = prob.num\n",
    "        M = prob.dimensions\n",
    "\n",
    "        x = prob.X\n",
    "        y = prob.Y\n",
    "\n",
    "        gamma = prob.gamma\n",
    "        delta = prob.delta\n",
    "\n",
    "        H11 = (prob.xi_xj * prob.yi_yj) + gamma*(prob.xstari_xstarj * prob.yi_yj)\n",
    "        H12 = -gamma*(prob.xstari_xstarj * prob.yi_yj)\n",
    "        H22 = gamma*(prob.xstari_xstarj * prob.yi_yj)\n",
    "        H1 = np.hstack((H11, H12))\n",
    "        H2 = np.hstack((H12, H22))\n",
    "        H = np.vstack((H1, H2))\n",
    "\n",
    "        f = np.hstack((np.repeat(-1, L),np.zeros(L)))\n",
    "\n",
    "        positiveEye = np.eye(L, dtype='d')\n",
    "        negativeEye = -np.eye(L, dtype='d')\n",
    "        zeros = np.zeros((L, L))\n",
    "        g1 = np.hstack((zeros, negativeEye))\n",
    "        g2 = np.hstack((zeros, positiveEye))\n",
    "        g3 = np.hstack((negativeEye, zeros))\n",
    "        g4 = np.hstack((positiveEye, negativeEye))\n",
    "\n",
    "        G = np.vstack((g1,g2))\n",
    "        G = np.vstack((G,g3))\n",
    "        G = np.vstack((G,g4))\n",
    "\n",
    "        h1 = np.zeros(((L),1))\n",
    "        h2 = np.repeat(C, (L)).reshape(-1,1)\n",
    "        h2 = np.vstack((h1, h2))\n",
    "        h3 = np.vstack((h2, h1))\n",
    "        h4 = np.repeat((delta*C), L).reshape(-1,1)\n",
    "        h = np.vstack((h3, h4))\n",
    "\n",
    "        Aeq1 = np.hstack((prob.Y, np.zeros(L)))\n",
    "        Aeq2 = np.hstack((np.zeros(L), prob.Y))\n",
    "        Aeq = np.vstack((Aeq1, Aeq2))\n",
    "\n",
    "        beq = np.zeros(2)\n",
    "        beq = beq.reshape(-1,1)\n",
    "\n",
    "        P = matrix(H, tc='d')\n",
    "        q = matrix(f, tc='d')\n",
    "        G = matrix(G, tc='d')\n",
    "        h = matrix(h, tc='d')\n",
    "        A = matrix(Aeq, tc='d')\n",
    "        b = matrix(beq, tc='d')\n",
    "\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alphasAndDeltas = np.array(sol['x'])\n",
    "        alphas = alphasAndDeltas[:L]\n",
    "        deltas = alphasAndDeltas[L:]\n",
    "        w = np.sum(alphas * y[:, None] * x, axis = 0)\n",
    "        bacond = (alphas > 1e-8)\n",
    "        bdcond = (deltas < C)\n",
    "        bxcond = (x != 0)\n",
    "\n",
    "        bxcond2 = list(range(0, L))\n",
    "        index = 0\n",
    "        for dataPoint in bxcond:\n",
    "            if np.any(dataPoint):\n",
    "                bxcond2[index] = True\n",
    "            else:\n",
    "                bxcond2[index] = False\n",
    "            index += 1\n",
    "\n",
    "        bcond = np.array([a and b for a, b in zip(bacond, bdcond)]).flatten()\n",
    "        bcond = np.array([a and b for a, b in zip(bcond, bxcond2)]).flatten()\n",
    "        yK = y[bcond]\n",
    "        xK = x[bcond]\n",
    "        \n",
    "        b = []\n",
    "        for k in range(len(xK)):\n",
    "            b.append(1-yK[k]*np.dot(w, xK[k]))\n",
    "        bias = (1- (sum(b) / len(b)))\n",
    "        \n",
    "        clf = classifier()\n",
    "        clf.w = w\n",
    "        clf.b = bias\n",
    "        clf.alphas = alphas\n",
    "        clf.support_vectors = x[bacond.flatten()]\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The other side!\n",
    "Phew, right, now we've done that. Let's see what we want to do. The plan is a follows.\n",
    "### The plan\n",
    "1) import some data, probably a small set so that we can look at it\n",
    "    \n",
    "    1.1) [This dataset](https://archive.ics.uci.edu/ml/datasets/Balloons) looks like it should do the job\n",
    "    \n",
    "2) Create 10 permutations of the data\n",
    "    \n",
    "3) Split each permutation into training and test data\n",
    "\n",
    "4) Split the data into $X$, $X^*$ and $Y$.\n",
    "\n",
    "5) Transform it so that we're dealing with numbers instead of text.\n",
    "\n",
    "6) See how well each classifier performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "So this is a tiny dataset. The plan is try small and work our way bigger. First we'll oad in the dataset. It's all strings, so let's just get it in, then we can start working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_array_from_file(file):\n",
    "    ''' Return the data from a file ignoring the column headers '''\n",
    "    array = np.loadtxt(file, delimiter=',', dtype=bytes).astype(str)\n",
    "    return array[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = get_array_from_file(\"adult+stretch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = np.array(data.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data follows a simple rule. If the balloon is owened by an adult and is \"stretched\", then it will be inflated (T), else it will not be inflated (F). \n",
    "\n",
    "Let's get some permuattions of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotate (X):\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNcopies(A, X):\n",
    "    nCopies = []\n",
    "    for i in range(A):\n",
    "        nCopies.append(np.copy(X))\n",
    "    return nCopies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffleCopies(copyList):\n",
    "    for copy in copyList:\n",
    "        rotate(copy)\n",
    "    return copyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copies = getNcopies(5, data)\n",
    "#shuffledCopies = shuffleCopies(copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X):\n",
    "    testSize = len(X)//1.001\n",
    "    trainSize = len(X) - testSize\n",
    "    return(X[:trainSize,:], X[trainSize:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_features_target(X, targetCol):\n",
    "    target = X[:,[targetCol]]\n",
    "    features = np.delete(X, targetCol, 1)\n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train, test = split_train_test(data)\n",
    "#train_features, train_target = split_features_target(train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_labels_to_classes(target):\n",
    "    lb = pp.LabelBinarizer(neg_label=-1)\n",
    "    y = lb.fit_transform(target).flatten()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t = target_labels_to_classes(train_target)\n",
    "#t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's start off by splitting this into features and a target, the converting the tearget to -1 and 1 for our binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lb = pp.LabelBinarizer(neg_label=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features = data[:,:-1]\n",
    "#target = data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lb.fit(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y = lb.transform(target).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we should decide what's privileged information ($X^*$). I'm going to suggest the stretch / dip attribute as this is important for classification, without it you can't have a reliable classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xStar = features[:,[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = np.delete(features, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to encode the data so that it's of a one-of-K form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enc = pp.LabelEncoder()\n",
    "#ohe = OneHotEncoder(sparse=False)\n",
    "#colour = enc.fit_transform(x[:,[0]].flatten()).reshape(-1,1)\n",
    "#colour = ohe.fit_transform(colour)\n",
    "#size = enc.fit_transform(x[:,[1]].flatten()).reshape(-1,1)\n",
    "#size = ohe.fit_transform(size)\n",
    "#age = enc.fit_transform(x[:,[2]].flatten()).reshape(-1,1)\n",
    "#age = ohe.fit_transform(age)\n",
    "#x = np.hstack((colour, size))\n",
    "#x = np.hstack((x, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xStar = enc.fit_transform(xStar.flatten()).reshape(-1,1)\n",
    "#xStar = ohe.fit_transform(xStar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prob = svm_problem()\n",
    "#prob.set_variables(x, xStar, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's just double check that the classifiers work and that there aren't any bugs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##svm = SVM()\n",
    "#svm_clf = svm.train(x, prob)\n",
    "#svmdp_simp = SVMdp_simp()\n",
    "#svmdpsimp_clf = svmdp_simp.train(prob)\n",
    "#svmdp = SVMdp()\n",
    "#svmdp_clf = svmdp.train(prob)\n",
    "#svm_clf.predict([0,0,0,0,0,0]), svmdpsimp_clf.predict([0,0,0,0,0,0]), svmdp_clf.predict([0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's cool. Now we know what we're going to do, we need to go about splitting the data into training and test data for various permutations. So we'll start from the begining set and create the folds, then preprocess, then test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructProblem(data, xIndices, xStarIndices, yIndex):\n",
    "    x = data[:,[xIndices]].astype(np.float)\n",
    "    x = x[:,0]\n",
    "    xStar = data[:,[xStarIndices]].astype(np.float)\n",
    "    xStar = xStar[:,0]\n",
    "    y = data[:,[yIndex]].astype(np.float).flatten()\n",
    "    prob = svm_problem()\n",
    "    prob.set_variables(x, xStar, y)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_copies_relabel_target(original_data, targetCol, copies):\n",
    "    lb = pp.LabelBinarizer(neg_label=-1)\n",
    "    features, target = split_features_target(original_data, targetCol)\n",
    "    lb.fit(target)\n",
    "    amended_copies = []\n",
    "    for copy in copies:\n",
    "        features, target = split_features_target(copy, targetCol)\n",
    "        target = lb.transform(target)\n",
    "        amended_copies.append(np.hstack((features, target)))\n",
    "    return amended_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def all_copies_relabel_feature(original_data, featCol, copys):\n",
    "    copies = np.copy(copys)\n",
    "    enc = pp.LabelEncoder()\n",
    "    feature_to_learn = original_data[:,[featCol]].flatten()\n",
    "    enc.fit(feature_to_learn)\n",
    "    amended_copies = []\n",
    "    for copy in copies:\n",
    "        feature = copy[:,[featCol]].flatten()\n",
    "        feature = enc.transform(feature).reshape(-1,1)\n",
    "        copy[:,[featCol]] = feature\n",
    "        amended_copies.append(copy)\n",
    "    return amended_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#h = all_copies_relabel_target(data, 4, shuffledCopies)\n",
    "#h = all_copies_relabel_feature(data, 0, h)\n",
    "#h = all_copies_relabel_feature(data, 1, h)\n",
    "#h = all_copies_relabel_feature(data, 2, h)\n",
    "#h = all_copies_relabel_feature(data, 3, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_xs_y(data, xIndices, xStarIndices, yIndex):\n",
    "    x = data[:,[xIndices]].astype(np.float)\n",
    "    x = x[:,0]\n",
    "    xStar = data[:,[xStarIndices]].astype(np.float)\n",
    "    xStar = xStar[:,0]\n",
    "    y = data[:,[yIndex]].astype(np.float).flatten()\n",
    "    return x, xStar, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(data, xIndices, xStarIndices, yIndex, model):\n",
    "    train, test = split_train_test(data)\n",
    "    train_prob = constructProblem(train, xIndices, xStarIndices, yIndex)\n",
    "    svm = model\n",
    "    \n",
    "    if isinstance(svm, SVM):\n",
    "        clf = svm.train(train_prob.X, train_prob)\n",
    "    else:\n",
    "        clf = svm.train(train_prob)\n",
    "    test_x, test_xs, test_y = get_x_xs_y(test, xIndices, xStarIndices, yIndex)\n",
    "    print(\"weight: \", clf.w)\n",
    "    print(\"bias: \", clf.b)\n",
    "    predictions = []\n",
    "    for test_point in test_x:\n",
    "        predictions.append(clf.predict(test_point))\n",
    "        \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == 1 and predictions[i] == 1:\n",
    "            tp += 1\n",
    "        if test_y[i] == -1 and predictions[i] == 1:\n",
    "            fp += 1\n",
    "        if test_y[i] == 1 and predictions[i] == -1:\n",
    "            fn += 1\n",
    "        if test_y[i] == -1 and predictions[i] == -1:\n",
    "            tn += 1\n",
    "    return (tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(tp, fp, fn, tn):\n",
    "    return (tp+tn)/(tp+fp+fn+tn+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error(tp, fp, fn, tn):\n",
    "    return (fp+fn)/(tp+fp+fn+tn+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recall(tp, fp, fn, tn):\n",
    "    return (tp)/(tp+fn+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_specificity(tp, fp, fn, tn):\n",
    "    return (tn)/(fp+tn+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_precision(tp, fp, fn, tn):\n",
    "    return (tp)/(tp+fp+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prevalence(tp, fp, fn, tn):\n",
    "    return (tp+fn)/(tp+fp+fn+tn+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_classifiers(shuffled):\n",
    "    clfs = [SVM(), SVMdp_simp(), SVMdp()]\n",
    "    x_in = [1,3,4,5,6,7,11,12]\n",
    "    xs_in = [0,8,9]\n",
    "    y_in = [14]\n",
    "\n",
    "    \n",
    "    for clf in clfs:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        average_time = 0\n",
    "        for permutation in shuffled:\n",
    "            start = timer()\n",
    "            a, b, c, d = train_and_test(permutation, x_in, xs_in, y_in, clf)\n",
    "            average_time += timer() - start\n",
    "            tp += a\n",
    "            fp += b\n",
    "            fn += c\n",
    "            tn += d\n",
    "        average_time = average_time/len(shuffled)\n",
    "        accuracy = get_accuracy(tp, fp, fn, tn)\n",
    "        error = get_error(tp, fp, fn, tn)\n",
    "        recall = get_recall(tp, fp, fn, tn)\n",
    "        specificity = get_specificity(tp, fp, fn, tn)\n",
    "        precision = get_precision(tp, fp, fn, tn)\n",
    "        prevalence = get_prevalence(tp, fp, fn, tn)\n",
    "        print(clf.get_name())\n",
    "        print(\"=====================================\")\n",
    "        print(\"|          |  Pred: YES |  Pred: NO |\")\n",
    "        print(\"+----------+------------+-----------+\")\n",
    "        print(\"| Act: YES |  \", '{:7d}'.format(tp), \" | \", '{:7d}'.format(fn), \" |\")\n",
    "        print(\"+----------+------------+-----------+\")\n",
    "        print(\"| Act: NO  |  \", '{:7d}'.format(fp), \" | \", '{:7d}'.format(tn), \" |\")\n",
    "        print(\"+----------+------------+-----------+\")\n",
    "        \n",
    "        print(\"accuracy = \", accuracy)\n",
    "        print(\"error = \", error)\n",
    "        print(\"recall = \", recall)\n",
    "        print(\"specificity = \", specificity)\n",
    "        print(\"precision = \", precision)\n",
    "        print(\"prevalence = \", prevalence)\n",
    "        print(\"average time to train classifier = \", average_time, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare_classifiers(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gawd I need to tidy the above up\n",
    "### But making progress, so just going to power on and come back to this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_array_from_file(\"adult.csv\")\n",
    "copies = getNcopies(5, data)\n",
    "shuffledCopies = shuffleCopies(copies)\n",
    "#shuffledCopies = []\n",
    "#shuffledCopies.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# This doesn't work - come back later\n",
    "#\n",
    "def all_copies_ohe_feature(copys, featCol):\n",
    "    \n",
    "    copies = np.copy(copys)\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    orig = copies[0]\n",
    "    print(orig[0])\n",
    "    feature_to_learn = orig[:,[featCol]]\n",
    "    print(feature_to_learn)\n",
    "    ohe.fit(feature_to_learn)\n",
    "    \n",
    "    amended_copies = []\n",
    "    for copy in copies:\n",
    "        feature = ohe.transform(copy[:,[featCol]])\n",
    "        amended_copies.append(feature)\n",
    "    return amended_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = all_copies_relabel_target(data, 14, shuffledCopies)\n",
    "h = all_copies_relabel_feature(data, 1, h)\n",
    "h = all_copies_relabel_feature(data, 2, h)\n",
    "h = all_copies_relabel_feature(data, 3, h)\n",
    "h = all_copies_relabel_feature(data, 4, h)\n",
    "h = all_copies_relabel_feature(data, 5, h)\n",
    "h = all_copies_relabel_feature(data, 6, h)\n",
    "h = all_copies_relabel_feature(data, 7, h)\n",
    "h = all_copies_relabel_feature(data, 8, h)\n",
    "h = all_copies_relabel_feature(data, 9, h)\n",
    "h = all_copies_relabel_feature(data, 10, h)\n",
    "h = all_copies_relabel_feature(data, 11, h)\n",
    "h = all_copies_relabel_feature(data, 12, h)\n",
    "h = all_copies_relabel_feature(data, 13, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverthomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  [  6.76459820e-02   9.42379482e-03  -5.01820701e-03  -4.51083398e-02\n",
      "   1.04839348e-02  -3.73629560e-02  -4.23699444e-07  -1.13586778e-03]\n",
      "bias:  -0.522030412355\n",
      "weight:  [-0.29701669 -0.0017198  -0.13251156 -0.07410763  0.08329104 -0.51116178\n",
      " -0.0519024  -0.02449697]\n",
      "bias:  -0.591666675459\n",
      "weight:  [ 0.23521469  0.02694045 -0.05022306  0.08455754  0.00975473 -0.16044242\n",
      "  0.03862242 -0.00975472]\n",
      "bias:  -0.14290308183\n",
      "weight:  [ 0.00231356  0.0517854   0.00297095 -0.01930693  0.04945561 -0.11506992\n",
      "  0.0419286  -0.00389398]\n",
      "bias:  -0.602777068958\n",
      "weight:  [ 0.08226012 -0.02948615 -0.0458581   0.02367448  0.01601924 -0.34065645\n",
      "  0.05865348  0.16189332]\n",
      "bias:  0.123155359185\n",
      "SVM\n",
      "=====================================\n",
      "|          |  Pred: YES |  Pred: NO |\n",
      "+----------+------------+-----------+\n",
      "| Act: YES |     19607  |    19558  |\n",
      "+----------+------------+-----------+\n",
      "| Act: NO  |     52428  |    71042  |\n",
      "+----------+------------+-----------+\n",
      "accuracy =  0.5573769483779175\n",
      "error =  0.4426230516159337\n",
      "recall =  0.5006255585216233\n",
      "specificity =  0.57537863448145\n",
      "precision =  0.2721871312518611\n",
      "prevalence =  0.24081532265354433\n",
      "average time to train classifier =  0.5880500804167241 \n",
      "\n",
      "weight:  [ 0.22626679  1.87441431 -1.29676833 -1.05095109  0.49570995 -0.75391831\n",
      " -1.0745162   3.95255219]\n",
      "bias:  [-0.40156643]\n",
      "weight:  [-0.61061322  1.58920226 -1.47784207 -0.44037833 -0.11452945 -0.62526557\n",
      " -2.75545024 -3.95302168]\n",
      "bias:  [-0.63307641]\n",
      "weight:  [ 1.16364096  0.38085986 -4.23299372 -0.90787422  1.95826764 -1.15492995\n",
      "  4.2         4.7149721 ]\n",
      "bias:  [-0.35242905]\n",
      "weight:  [ 0.51737587  0.51577194 -2.22564382 -0.72933584  2.6749323  -0.8196843\n",
      "  3.89999998  5.11448706]\n",
      "bias:  [-0.63705027]\n",
      "weight:  [  0.7717173    3.25243858  -5.85474598   0.61163961   0.38693063\n",
      "  -1.49029082  10.39999999  17.20047907]\n",
      "bias:  [-0.33902021]\n",
      "SVM+ - simplified approach\n",
      "=====================================\n",
      "|          |  Pred: YES |  Pred: NO |\n",
      "+----------+------------+-----------+\n",
      "| Act: YES |     31290  |     7875  |\n",
      "+----------+------------+-----------+\n",
      "| Act: NO  |     97729  |    25741  |\n",
      "+----------+------------+-----------+\n",
      "accuracy =  0.3506686752522479\n",
      "error =  0.6493313247416034\n",
      "recall =  0.7989276139206197\n",
      "specificity =  0.20847979266049665\n",
      "precision =  0.24252241917669087\n",
      "prevalence =  0.24081532265354433\n",
      "average time to train classifier =  0.9543510066112504 \n",
      "\n",
      "weight:  [  2.58937872  15.5674224   -5.71205501  -8.2001845    8.64557583\n",
      "  -5.63648405  -8.37754536  43.1419867 ]\n",
      "bias:  -773.066580597\n",
      "weight:  [ -6.37968645  17.64438363 -13.76884293  -5.13347334   1.20132536\n",
      "  -6.85430102 -27.62532313 -42.31277755]\n",
      "bias:  1037.25288953\n",
      "weight:  [  9.01881974  -5.71898187 -24.1944129   -5.90758517  20.08840933\n",
      "  -9.21884894  52.64102638  53.2809002 ]\n",
      "bias:  -409.6209129\n",
      "weight:  [  5.33441908   9.30740189 -16.59311587  -8.05602302  23.48763435\n",
      "  -8.40968593  54.47880858  45.87131213]\n",
      "bias:  -849.20926327\n",
      "weight:  [   1.37579271   23.93149532  -35.80919324    6.08517619   -1.2258328\n",
      "   -9.00800415  125.06844171  103.33231987]\n",
      "bias:  -362.698660825\n",
      "SVM+\n",
      "=====================================\n",
      "|          |  Pred: YES |  Pred: NO |\n",
      "+----------+------------+-----------+\n",
      "| Act: YES |     31263  |     7902  |\n",
      "+----------+------------+-----------+\n",
      "| Act: NO  |     96387  |    27083  |\n",
      "+----------+------------+-----------+\n",
      "accuracy =  0.3587542656847618\n",
      "error =  0.6412457343090894\n",
      "recall =  0.7982382228827208\n",
      "specificity =  0.21934882967344824\n",
      "precision =  0.24491186838821066\n",
      "prevalence =  0.24081532265354433\n",
      "average time to train classifier =  0.5572648406028747 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_classifiers(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
